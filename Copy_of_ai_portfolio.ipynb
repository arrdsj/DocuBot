{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be58b994-bc68-4166-91d5-282418b78864",
      "metadata": {
        "id": "be58b994-bc68-4166-91d5-282418b78864"
      },
      "source": [
        "# Project: Portfolio - Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5120b06-0abf-49e3-b54d-db8afa9eda01",
      "metadata": {
        "id": "c5120b06-0abf-49e3-b54d-db8afa9eda01"
      },
      "source": [
        "**Instructions for Students:**\n",
        "\n",
        "Please carefully follow these steps to complete and submit your assignment:\n",
        "\n",
        "1. **Completing the Assignment**: You are required to work on and complete all tasks in the provided assignment. Be disciplined and ensure that you thoroughly engage with each task.\n",
        "   \n",
        "2. **Creating a Google Drive Folder**: If you don't previously have a folder for collecting assignments, you must create a new folder in your Google Drive. This will be a repository for all your completed assignment files, helping you keep your work organized and easy to access.\n",
        "   \n",
        "3. **Uploading Completed Assignment**: Upon completion of your assignment, make sure to upload all necessary files, involving codes, reports, and related documents into the created Google Drive folder. Save this link in the 'Student Identity' section and also provide it as the last parameter in the `submit` function that has been provided.\n",
        "   \n",
        "4. **Sharing Folder Link**: You're required to share the link to your assignment Google Drive folder. This is crucial for the submission and evaluation of your assignment.\n",
        "   \n",
        "5. **Setting Permission toPublic**: Please make sure your **Google Drive folder is set to public**. This allows your instructor to access your solutions and assess your work correctly.\n",
        "\n",
        "Adhering to these procedures will facilitate a smooth assignment process for you and the reviewers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca56111-19cb-46c0-a77b-11bd18c55673",
      "metadata": {
        "id": "eca56111-19cb-46c0-a77b-11bd18c55673"
      },
      "source": [
        "**Description:**\n",
        "\n",
        "Welcome to your final portfolio project assignment for AI Bootcamp. This is your chance to put all the skills and knowledge you've learned throughout the bootcamp into action by creating real-world AI application.\n",
        "\n",
        "You have the freedom to create any application or model, be it text-based or image-based or even voice-based or multimodal.\n",
        "\n",
        "To get you started, here are some ideas:\n",
        "\n",
        "1. **Sentiment Analysis Application:** Develop an application that can determine sentiment (positive, negative, neutral) from text data like reviews or social media posts. You can use Natural Language Processing (NLP) libraries like NLTK or TextBlob, or more advanced pre-trained models from transformers library by Hugging Face, for your sentiment analysis model.\n",
        "\n",
        "2. **Chatbot:** Design a chatbot serving a specific purpose such as customer service for a certain industry, a personal fitness coach, or a study helper. Libraries like ChatterBot or Dialogflow can assist in designing conversational agents.\n",
        "\n",
        "3. **Predictive Text Application:** Develop a model that suggests the next word or sentence similar to predictive text on smartphone keyboards. You could use the transformers library by Hugging Face, which includes pre-trained models like GPT-2.\n",
        "\n",
        "4. **Image Classification Application:** Create a model to distinguish between different types of flowers or fruits. For this type of image classification task, pre-trained models like ResNet or VGG from PyTorch or TensorFlow can be utilized.\n",
        "\n",
        "5. **News Article Classifier:** Develop a text classification model that categorizes news articles into predefined categories. NLTK, SpaCy, and sklearn are valuable libraries for text pre-processing, feature extraction, and building classification models.\n",
        "\n",
        "6. **Recommendation System:** Create a simplified recommendation system. For instance, a book or movie recommender based on user preferences. Python's Surprise library can assist in building effective recommendation systems.\n",
        "\n",
        "7. **Plant Disease Detection:** Develop a model to identify diseases in plants using leaf images. This project requires a good understanding of convolutional neural networks (CNNs) and image processing. PyTorch, TensorFlow, and OpenCV are all great tools to use.\n",
        "\n",
        "8. **Facial Expression Recognition:** Develop a model to classify human facial expressions. This involves complex feature extraction and classification algorithms. You might want to leverage deep learning libraries like TensorFlow or PyTorch, along with OpenCV for processing facial images.\n",
        "\n",
        "9. **Chest X-Ray Interpretation:** Develop a model to detect abnormalities in chest X-ray images. This task may require understanding of specific features in such images. Again, TensorFlow and PyTorch for deep learning, and libraries like SciKit-Image or PIL for image processing, could be of use.\n",
        "\n",
        "10. **Food Classification:** Develop a model to classify a variety of foods such as local Indonesian food. Pre-trained models like ResNet or VGG from PyTorch or TensorFlow can be a good starting point.\n",
        "\n",
        "11. **Traffic Sign Recognition:** Design a model to recognize different traffic signs. This project has real-world applicability in self-driving car technology. Once more, you might utilize PyTorch or TensorFlow for the deep learning aspect, and OpenCV for image processing tasks.\n",
        "\n",
        "**Submission:**\n",
        "\n",
        "Please upload both your model and application to Huggingface or your own Github account for submission.\n",
        "\n",
        "**Presentation:**\n",
        "\n",
        "You are required to create a presentation to showcase your project, including the following details:\n",
        "\n",
        "- The objective of your model.\n",
        "- A comprehensive description of your model.\n",
        "- The specific metrics used to measure your model's effectiveness.\n",
        "- A brief overview of the dataset used, including its source, pre-processing steps, and any insights.\n",
        "- An explanation of the methodology used in developing the model.\n",
        "- A discussion on challenges faced, how they were handled, and your learnings from those.\n",
        "- Suggestions for potential future improvements to the model.\n",
        "- A functioning link to a demo of your model in action.\n",
        "\n",
        "**Grading:**\n",
        "\n",
        "Submissions will be manually graded, with a select few given the opportunity to present their projects in front of a panel of judges. This will provide valuable feedback, further enhancing your project and expanding your knowledge base.\n",
        "\n",
        "Remember, consistent practice is the key to mastering these concepts. Apply your knowledge, ask questions when in doubt, and above all, enjoy the process. Best of luck to you all!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "213a611a-c434-4894-ba35-689963ee5274",
      "metadata": {
        "id": "213a611a-c434-4894-ba35-689963ee5274"
      },
      "outputs": [],
      "source": [
        "# @title #### Student Identity\n",
        "student_id = \"REA6HXRRQ\" # @param {type:\"string\"}\n",
        "name = \"Ratih Dewi Setyo Jati\" # @param {type:\"string\"}\n",
        "drive_link = \"https://drive.google.com/drive/folders/1Vrjou0HK9_7a2qA6abCbjXJA6WRDqzBU?usp=sharing\"  # @param {type:\"string\"}\n",
        "assignment_id = \"00_portfolio_project\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c97aef3-b747-49f7-99e0-4086c03e4200",
      "metadata": {
        "id": "2c97aef3-b747-49f7-99e0-4086c03e4200"
      },
      "source": [
        "## Installation and Import `rggrader` Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "36c07e23-0280-467f-b0d2-44d966253bb4",
      "metadata": {
        "id": "36c07e23-0280-467f-b0d2-44d966253bb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae33d9f-55fc-4336-faef-2c78c73ebeae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rggrader in /usr/local/lib/python3.11/dist-packages (0.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from rggrader) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from rggrader) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rggrader) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->rggrader) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->rggrader) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->rggrader) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->rggrader) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->rggrader) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->rggrader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->rggrader) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->rggrader) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->rggrader) (1.17.0)\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-all is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-ind is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "ghostscript is already the newest version (9.55.0~dfsg1-0ubuntu5.11).\n",
            "libmagic-dev is already the newest version (1:5.41-3ubuntu0.1).\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.7).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement python-magic-bin (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for python-magic-bin\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install rggrader\n",
        "from rggrader import submit_image\n",
        "from rggrader import submit\n",
        "\n",
        "# ============== INSTALL DEPENDENCIES ==============\n",
        "!pip install -q gradio langchain langchain-google-genai langchain-community pandas pypdf faiss-cpu openpyxl\n",
        "!sudo apt update\n",
        "!sudo apt install -y tesseract-ocr tesseract-ocr-ind tesseract-ocr-all poppler-utils ghostscript libmagic-dev\n",
        "!pip install -q unstructured[pdf] pdf2image pytesseract ocrmypdf python-magic python-magic-bin"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4af3420-ff0e-472b-8b44-7a495ddf76c3",
      "metadata": {
        "id": "a4af3420-ff0e-472b-8b44-7a495ddf76c3"
      },
      "source": [
        "## Working Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c1fb239a-1c81-4476-9009-d87abadf9506",
      "metadata": {
        "id": "c1fb239a-1c81-4476-9009-d87abadf9506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7935a12-1d06-4419-bb16-1bf5ec20ab8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Masukkan Google Gemini API Key: AIzaSyC4C22jUntWRkYJfQrR2k2RgRnL07FoIC0\n",
            "\n",
            "📂 Memulai pemrosesan dokumen di folder: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/\n",
            "\n",
            "🔍 Memeriksa file: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Pengumuman Libur Nasional dan Cuti Bersama 2025.pdf\n",
            "   🔵 File PDF terdeteksi\n",
            "\n",
            "🔍 Mencoba membaca file PDF: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Pengumuman Libur Nasional dan Cuti Bersama 2025.pdf\n",
            "   🧠 Mencoba ekstraksi teks terstruktur...\n",
            "   👀 Teks sedikit, mencoba OCR...\n",
            "❌ Gagal memproses PDF /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Pengumuman Libur Nasional dan Cuti Bersama 2025.pdf: unstructured package not found, please install it with `pip install unstructured`\n",
            "\n",
            "🔍 Memeriksa file: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/JADWAL HD PSS APRIL 2025.xlsx\n",
            "   🟢 File Excel terdeteksi\n",
            "\n",
            "🔍 Mencoba membaca file Excel: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/JADWAL HD PSS APRIL 2025.xlsx\n",
            "   📊 Memproses sheet: Sheet1\n",
            "⚠️ File Excel tidak mengandung data jadwal: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/JADWAL HD PSS APRIL 2025.xlsx\n",
            "   ✔️ Berhasil memproses file: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/JADWAL HD PSS APRIL 2025.xlsx\n",
            "\n",
            "🔍 Memeriksa file: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage + Onsite March 2025 - Tim Infraops System engineer-DBA.xlsx\n",
            "   🟢 File Excel terdeteksi\n",
            "\n",
            "🔍 Mencoba membaca file Excel: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage + Onsite March 2025 - Tim Infraops System engineer-DBA.xlsx\n",
            "   📊 Memproses sheet: COVERAGE (REMOTE SUPPORT)\n",
            "   ⚙️ Format terdeteksi: TIM 2 Network\n",
            "   📊 Memproses sheet: COVERAGE (REMOTE SUPPORT) (2)\n",
            "   ⚙️ Format terdeteksi: TIM 2 Network\n",
            "   📊 Memproses sheet: JADWAL WFO\n",
            "⚠️ File Excel tidak mengandung data jadwal: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage + Onsite March 2025 - Tim Infraops System engineer-DBA.xlsx\n",
            "   ✔️ Berhasil memproses file: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage + Onsite March 2025 - Tim Infraops System engineer-DBA.xlsx\n",
            "\n",
            "🔍 Memeriksa file: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage ODE4.xlsx\n",
            "   🟢 File Excel terdeteksi\n",
            "\n",
            "🔍 Mencoba membaca file Excel: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage ODE4.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/unstructured.py\", line 59, in __init__\n",
            "    import unstructured  # noqa:F401\n",
            "    ^^^^^^^^^^^^^^^^^^^\n",
            "ModuleNotFoundError: No module named 'unstructured'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-12-ab4ed207ea60>\", line 280, in process_pdf\n",
            "    loader = UnstructuredPDFLoader(filepath)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/pdf.py\", line 89, in __init__\n",
            "    super().__init__(file_path=file_path, mode=mode, **unstructured_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\", line 221, in warn_if_direct_instance\n",
            "    return wrapped(self, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/unstructured.py\", line 213, in __init__\n",
            "    super().__init__(mode=mode, **unstructured_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/unstructured.py\", line 61, in __init__\n",
            "    raise ImportError(\n",
            "ImportError: unstructured package not found, please install it with `pip install unstructured`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   📊 Memproses sheet: 2301\n",
            "   📊 Memproses sheet: 2302\n",
            "   📊 Memproses sheet: 2303\n",
            "   📊 Memproses sheet: 2304\n",
            "   📊 Memproses sheet: 2305\n",
            "   📊 Memproses sheet: 2306\n",
            "   📊 Memproses sheet: 2307\n",
            "   📊 Memproses sheet: 2308\n",
            "   📊 Memproses sheet: 2309\n",
            "   📊 Memproses sheet: 2310\n",
            "   📊 Memproses sheet: 2311\n",
            "   📊 Memproses sheet: 2312\n",
            "   📊 Memproses sheet: 2401\n",
            "   📊 Memproses sheet: 2402\n",
            "   📊 Memproses sheet: 2403\n",
            "   📊 Memproses sheet: 2404\n",
            "   📊 Memproses sheet: 2405\n",
            "   📊 Memproses sheet: 2406\n",
            "   📊 Memproses sheet: 2407\n",
            "   📊 Memproses sheet: 2408\n",
            "   📊 Memproses sheet: 2409\n",
            "   📊 Memproses sheet: 2410\n",
            "   📊 Memproses sheet: 2411\n",
            "   📊 Memproses sheet: 2412\n",
            "   📊 Memproses sheet: 2501\n",
            "   📊 Memproses sheet: 2502\n",
            "   📊 Memproses sheet: 2503\n",
            "   📊 Memproses sheet: 2504\n",
            "   📊 Memproses sheet: Contact PIC\n",
            "   📊 Memproses sheet: Klasifikasi Flight & Crew Mgt\n",
            "⚠️ File Excel tidak mengandung data jadwal: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage ODE4.xlsx\n",
            "   ✔️ Berhasil memproses file: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage ODE4.xlsx\n",
            "\n",
            "🔍 Memeriksa file: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage tim Network OIO-2 Maret 2025.xlsx\n",
            "   🟢 File Excel terdeteksi\n",
            "\n",
            "🔍 Mencoba membaca file Excel: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage tim Network OIO-2 Maret 2025.xlsx\n",
            "   📊 Memproses sheet: Maret\n",
            "   ⚙️ Format terdeteksi: TIM 2 Network\n",
            "⚠️ File Excel tidak mengandung data jadwal: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage tim Network OIO-2 Maret 2025.xlsx\n",
            "   ✔️ Berhasil memproses file: /content/drive/My Drive/Final Project Bootcamp/chatbot_docs/Jadwal Coverage tim Network OIO-2 Maret 2025.xlsx\n",
            "\n",
            "📊 Ringkasan Pemrosesan:\n",
            "   Total file ditemukan: 5\n",
            "   File berhasil diproses: 4\n",
            "   File gagal diproses: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5aaae35c4998e9cb9d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5aaae35c4998e9cb9d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ============== IMPORT LIBRARIES ==============\n",
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.document_loaders import PyPDFLoader, UnstructuredPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "from google.colab import drive\n",
        "from openpyxl import load_workbook\n",
        "from typing import List, Dict, Tuple\n",
        "import re\n",
        "\n",
        "# ============== INITIAL SETUP ==============\n",
        "drive.mount('/content/drive')\n",
        "api_key = input(\"Masukkan Google Gemini API Key: \")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "\n",
        "# ============== EXCEL PROCESSORS ==============\n",
        "def parse_tim1_schedule(sheet) -> List[Dict]:\n",
        "    \"\"\"Parse Tim 1 (Shift P/S/M/L)\"\"\"\n",
        "    schedules = []\n",
        "    date_row = 3  # Baris tanggal\n",
        "\n",
        "    for row_idx in range(4, sheet.max_row + 1):\n",
        "        name = str(sheet.cell(row=row_idx, column=1).value).strip()\n",
        "        if not name or name in ['Date', 'Day', 'Shift']:\n",
        "            continue\n",
        "\n",
        "        shifts = []\n",
        "        for col_idx in range(2, 33):  # Kolom B-AF (tanggal 1-31)\n",
        "            date = sheet.cell(row=date_row, column=col_idx).value\n",
        "            shift = str(sheet.cell(row=row_idx, column=col_idx).value).strip().upper()\n",
        "\n",
        "            # Periksa warna sel untuk cuti/lembur/izin\n",
        "            cell = sheet.cell(row=row_idx, column=col_idx)\n",
        "            fill_color = cell.fill.start_color.index if cell.fill.start_color else None\n",
        "\n",
        "            status = None\n",
        "            if fill_color:\n",
        "                if fill_color == 'FFFFFF00':  # Kuning - Cuti\n",
        "                    status = 'Cuti'\n",
        "                elif fill_color == 'FF00B050':  # Hijau - Lembur\n",
        "                    status = 'Lembur'\n",
        "                elif fill_color == 'FFFE9666':  # Orange - Izin\n",
        "                    status = 'Izin'\n",
        "                elif fill_color == 'FFFF0000':  # Merad - Tanggal Merah\n",
        "                    status = 'Libur Nasional'\n",
        "\n",
        "            if date and shift in ['P', 'S', 'M', 'L', 'C']:\n",
        "                shifts.append({\n",
        "                    \"date\": date,\n",
        "                    \"shift\": shift,\n",
        "                    \"person\": name,\n",
        "                    \"status\": status\n",
        "                })\n",
        "\n",
        "        if shifts:\n",
        "            schedules.extend(shifts)\n",
        "\n",
        "    return schedules\n",
        "\n",
        "def parse_tim2_network(sheet) -> List[Dict]:\n",
        "    \"\"\"Parse Tim 2 Network Schedule (mulai dari B3) khusus Net-Eng\"\"\"\n",
        "    schedules = []\n",
        "\n",
        "    # Deteksi header - cari \"PIC\" di B3\n",
        "    if str(sheet.cell(row=3, column=2).value).strip() != \"PIC\":\n",
        "        return schedules\n",
        "\n",
        "    # Ambil data tanggal dan hari\n",
        "    dates = []\n",
        "    day_names = []\n",
        "    for col_idx in range(3, sheet.max_column + 1):\n",
        "        date_val = sheet.cell(row=4, column=col_idx).value  # Tanggal di row 4\n",
        "        day_val = sheet.cell(row=3, column=col_idx).value   # Hari di row 3\n",
        "        if date_val and day_val:\n",
        "            dates.append(date_val)\n",
        "            day_names.append(str(day_val).strip())\n",
        "\n",
        "    # Proses data person\n",
        "    for row_idx in range(5, sheet.max_row + 1):\n",
        "        name = str(sheet.cell(row=row_idx, column=2).value).strip()\n",
        "        if not name or name == \"Akumulasi\":\n",
        "            break\n",
        "\n",
        "        for col_idx in range(3, len(dates) + 3):\n",
        "            if col_idx > sheet.max_column:\n",
        "                break\n",
        "\n",
        "            if str(sheet.cell(row=row_idx, column=col_idx).value).strip().upper() == \"NET-ENG\":\n",
        "                day = day_names[col_idx-3]\n",
        "                schedules.append({\n",
        "                    \"date\": dates[col_idx-3],\n",
        "                    \"day\": day,\n",
        "                    \"shift\": \"Net-Eng\",\n",
        "                    \"person\": name,\n",
        "                    \"status\": \"Standby\",\n",
        "                    \"coverage\": \"All Day\" if day in [\"Sabtu\", \"Minggu\"] else \"17:00-06:00\"\n",
        "                })\n",
        "\n",
        "    return schedules\n",
        "\n",
        "def parse_tim3_infra(sheet) -> List[Dict]:\n",
        "    \"\"\"Parse Tim 3 Infra (SYSENG/DBA) mulai dari B3\"\"\"\n",
        "    schedules = []\n",
        "\n",
        "    # Deteksi header di B3\n",
        "    if str(sheet.cell(row=3, column=2).value).strip() != \"PIC\":\n",
        "        return schedules\n",
        "\n",
        "    # Ambil data tanggal dan hari\n",
        "    dates = []\n",
        "    day_names = []\n",
        "    for col_idx in range(3, sheet.max_column + 1):\n",
        "        date_val = sheet.cell(row=5, column=col_idx).value\n",
        "        day_val = str(sheet.cell(row=4, column=col_idx).value).strip()\n",
        "        if date_val and day_val:\n",
        "            dates.append(date_val)\n",
        "            day_names.append(day_val)\n",
        "\n",
        "    # Proses data person\n",
        "    for row_idx in range(6, sheet.max_row + 1):\n",
        "        name = str(sheet.cell(row=row_idx, column=2).value).strip()\n",
        "        if not name or name == \"Akumulasi\":\n",
        "            break\n",
        "\n",
        "        for col_idx in range(3, len(dates) + 3):\n",
        "            if col_idx > sheet.max_column:\n",
        "                break\n",
        "\n",
        "            cell_value = str(sheet.cell(row=row_idx, column=col_idx).value).strip().upper()\n",
        "            shift = \"SYSENG\" if cell_value == \"ENGINERING\" else cell_value\n",
        "\n",
        "            if shift in [\"SYSENG\", \"DBA\"]:\n",
        "                day = day_names[col_idx-3]\n",
        "                schedules.append({\n",
        "                    \"date\": dates[col_idx-3],\n",
        "                    \"day\": day,\n",
        "                    \"shift\": shift,\n",
        "                    \"person\": name,\n",
        "                    \"coverage\": \"All Day\" if day in [\"Sabtu\", \"Minggu\"] else \"17:00-06:00\"\n",
        "                })\n",
        "\n",
        "    return schedules\n",
        "\n",
        "def parse_tim4_schedule(sheet) -> List[Dict]:\n",
        "    \"\"\"Parse Tim 4 (FLIGHT MANAGEMENT/CREW MANAGEMENT/AMALA - ANTEROS/TIBCO ESB & BUMBLEBEE/SIIO - AJC)\"\"\"\n",
        "    schedules = []\n",
        "\n",
        "    # Deteksi header\n",
        "    header_row = None\n",
        "    for row_idx in range(1, 10):\n",
        "        if str(sheet.cell(row=row_idx, column=1).value).strip() == \"Date\":\n",
        "            header_row = row_idx\n",
        "            break\n",
        "\n",
        "    if not header_row:\n",
        "        return []\n",
        "\n",
        "    # Ambil data roles\n",
        "    roles = []\n",
        "    for col_idx in range(3, sheet.max_column + 1, 2):\n",
        "        role = str(sheet.cell(row=header_row-1, column=col_idx).value).strip()\n",
        "        if role:\n",
        "            roles.append(role)\n",
        "\n",
        "    # Proses jadwal\n",
        "    for row_idx in range(header_row+1, sheet.max_row + 1):\n",
        "        date_val = sheet.cell(row=row_idx, column=1).value\n",
        "        day_val = str(sheet.cell(row=row_idx, column=2).value).strip()\n",
        "\n",
        "        if not date_val:\n",
        "            continue\n",
        "\n",
        "        for role_idx, role in enumerate(roles):\n",
        "            day_col = 3 + (role_idx * 2)\n",
        "            night_col = day_col + 1\n",
        "\n",
        "            person_day = str(sheet.cell(row=row_idx, column=day_col).value).strip()\n",
        "            if person_day:\n",
        "                schedules.append({\n",
        "                    \"date\": date_val,\n",
        "                    \"day\": day_val,\n",
        "                    \"role\": role,\n",
        "                    \"shift\": \"Day (05:00-18:00)\",\n",
        "                    \"person\": person_day\n",
        "                })\n",
        "\n",
        "            person_night = str(sheet.cell(row=row_idx, column=night_col).value).strip()\n",
        "            if person_night:\n",
        "                schedules.append({\n",
        "                    \"date\": date_val,\n",
        "                    \"day\": day_val,\n",
        "                    \"role\": role,\n",
        "                    \"shift\": \"Night (17:00-06:00)\",\n",
        "                    \"person\": person_night\n",
        "                })\n",
        "\n",
        "    return schedules\n",
        "\n",
        "# ============== DOCUMENT PROCESSORS ==============\n",
        "def process_excel(filepath: str) -> str:\n",
        "    \"\"\"Process all Excel formats\"\"\"\n",
        "    try:\n",
        "        print(f\"\\n🔍 Mencoba membaca file Excel: {filepath}\")\n",
        "        wb = load_workbook(filename=filepath, data_only=True)\n",
        "        result = []\n",
        "\n",
        "        for sheet_name in wb.sheetnames:\n",
        "            sheet = wb[sheet_name]\n",
        "            print(f\"   📊 Memproses sheet: {sheet_name}\")\n",
        "\n",
        "            # Deteksi format sheet\n",
        "            if \"SHIFT 1\" in str(sheet.cell(row=3, column=1).value):\n",
        "                print(\"   ⚙️ Format terdeteksi: TIM 1 (Shift P/S/M/L)\")\n",
        "                data = parse_tim1_schedule(sheet)\n",
        "                result.append(f\"=== TIM 1 ({sheet_name}) ===\\n\")\n",
        "                for d in data:\n",
        "                    status_info = f\" ({d['status']})\" if d['status'] else \"\"\n",
        "                    result.append(f\"{d['person']} - {d['date']}: Shift {d['shift']}{status_info}\")\n",
        "\n",
        "            elif str(sheet.cell(row=3, column=2).value).strip() == \"PIC\":\n",
        "                print(\"   ⚙️ Format terdeteksi: TIM 2 Network\")\n",
        "                data = parse_tim2_network(sheet)\n",
        "                if data:\n",
        "                    result.append(f\"=== TIM 2 Network ({sheet_name}) ===\\n\")\n",
        "                    for d in data:\n",
        "                        result.append(f\"{d['person']} - {d['date']} ({d['day']}): {d['shift']} ({d['coverage']})\")\n",
        "\n",
        "            elif str(sheet.cell(row=3, column=2).value).strip() == \"PIC\":\n",
        "                print(\"   ⚙️ Format terdeteksi: TIM 3 Infra\")\n",
        "                data = parse_tim3_infra(sheet)\n",
        "                if data:\n",
        "                    result.append(f\"=== TIM 3 Infra ({sheet_name}) ===\\n\")\n",
        "                    for d in data:\n",
        "                        coverage = \"All Day\" if d['day'] in [\"Sabtu\", \"Minggu\"] else \"17:00-06:00\"\n",
        "                        result.append(f\"{d['person']} - {d['date']} ({d['day']}): {d['shift']} ({coverage})\")\n",
        "\n",
        "            elif \"JADWAL TIM 4\" in str(sheet.cell(row=1, column=1).value):\n",
        "                print(\"   ⚙️ Format terdeteksi: TIM 4\")\n",
        "                data = parse_tim4_schedule(sheet)\n",
        "                if data:\n",
        "                    result.append(f\"=== TIM 4 ({sheet_name}) ===\\n\")\n",
        "                    for d in data:\n",
        "                        result.append(f\"{d['date']} ({d['day']}): {d['role']} - {d['shift']} - {d['person']}\")\n",
        "\n",
        "        if result:\n",
        "            print(f\"✅ Berhasil memproses file Excel: {filepath}\")\n",
        "            return \"\\n\".join(result)\n",
        "        else:\n",
        "            print(f\"⚠️ File Excel tidak mengandung data jadwal: {filepath}\")\n",
        "            return \"Tidak ada data jadwal yang ditemukan\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Gagal memproses file Excel {filepath}: {str(e)}\")\n",
        "        # Tambahan info error detail\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return f\"Error processing Excel: {str(e)}\"\n",
        "\n",
        "def process_pdf(filepath: str) -> str:\n",
        "    \"\"\"Extract text from PDF with fallback\"\"\"\n",
        "    try:\n",
        "        print(f\"\\n🔍 Mencoba membaca file PDF: {filepath}\")\n",
        "\n",
        "        # Coba metode terstruktur dulu\n",
        "        print(\"   🧠 Mencoba ekstraksi teks terstruktur...\")\n",
        "        loader = PyPDFLoader(filepath)\n",
        "        pages = loader.load()\n",
        "        text = \"\\n\".join([p.page_content for p in pages])\n",
        "\n",
        "        # Jika hasil kosong, coba metode OCR\n",
        "        if len(text.strip()) < 50:\n",
        "            print(\"   👀 Teks sedikit, mencoba OCR...\")\n",
        "            loader = UnstructuredPDFLoader(filepath)\n",
        "            docs = loader.load()\n",
        "            text = \"\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        if text.strip():\n",
        "            print(f\"✅ Berhasil mengekstrak teks dari PDF: {filepath}\")\n",
        "            print(f\"   Jumlah karakter: {len(text)}\")\n",
        "            return text\n",
        "        else:\n",
        "            print(f\"⚠️ PDF kosong/tidak terbaca: {filepath}\")\n",
        "            return \"PDF kosong/tidak terbaca\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Gagal memproses PDF {filepath}: {str(e)}\")\n",
        "        # Tambahan info error detail\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return f\"Error processing PDF: {str(e)}\"\n",
        "\n",
        "def load_documents(folder_path: str) -> List[Document]:\n",
        "    \"\"\"Load and process all documents\"\"\"\n",
        "    print(f\"\\n📂 Memulai pemrosesan dokumen di folder: {folder_path}\")\n",
        "    documents = []\n",
        "    total_files = 0\n",
        "    success_files = 0\n",
        "\n",
        "    for filepath in glob(os.path.join(folder_path, '*')):\n",
        "        total_files += 1\n",
        "        try:\n",
        "            print(f\"\\n🔍 Memeriksa file: {filepath}\")\n",
        "\n",
        "            if filepath.lower().endswith(('.xlsx', '.xls')):\n",
        "                print(\"   🟢 File Excel terdeteksi\")\n",
        "                content = process_excel(filepath)\n",
        "                metadata = {\n",
        "                    \"source\": os.path.basename(filepath),\n",
        "                    \"type\": \"excel\",\n",
        "                    \"format\": \"jadwal_tim\"\n",
        "                }\n",
        "            elif filepath.lower().endswith('.pdf'):\n",
        "                print(\"   🔵 File PDF terdeteksi\")\n",
        "                content = process_pdf(filepath)\n",
        "                metadata = {\n",
        "                    \"source\": os.path.basename(filepath),\n",
        "                    \"type\": \"pdf\",\n",
        "                    \"format\": \"libur_nasional\"\n",
        "                }\n",
        "            else:\n",
        "                print(f\"   ⚠️ Format tidak didukung: {filepath}\")\n",
        "                continue\n",
        "\n",
        "            if content and not content.startswith(\"Error\"):\n",
        "                documents.append(Document(\n",
        "                    page_content=content,\n",
        "                    metadata=metadata\n",
        "                ))\n",
        "                success_files += 1\n",
        "                print(f\"   ✔️ Berhasil memproses file: {filepath}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Gagal memproses {filepath}: {str(e)}\")\n",
        "            # Tambahan info error detail\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    print(f\"\\n📊 Ringkasan Pemrosesan:\")\n",
        "    print(f\"   Total file ditemukan: {total_files}\")\n",
        "    print(f\"   File berhasil diproses: {success_files}\")\n",
        "    print(f\"   File gagal diproses: {total_files - success_files}\")\n",
        "\n",
        "    return documents\n",
        "\n",
        "# ============== CHATBOT SETUP ==============\n",
        "template = \"\"\"ANALISIS JADWAL TIM:\n",
        "Anda adalah asisten yang membantu menjawab pertanyaan tentang jadwal tim. Gunakan data berikut untuk menjawab:\n",
        "\n",
        "{context}\n",
        "\n",
        "Pertanyaan: {question}\n",
        "\n",
        "FORMAT JAWABAN:\n",
        "1. Jenis Dokumen: {doc_type}\n",
        "2. Format: {format}\n",
        "3. Ringkasan: Berisi informasi tentang {content_summary}\n",
        "4. Detail: {answer}\n",
        "5. Sumber: {source}\n",
        "\n",
        "Gunakan bahasa Indonesia yang jelas dan ramah. Jika ada ketidakjelasan, sampaikan dengan sopan.\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "def format_docs(docs: List[Document]) -> str:\n",
        "    \"\"\"Format documents for context\"\"\"\n",
        "    formatted = []\n",
        "    for doc in docs:\n",
        "        content_summary = \"jadwal tim\" if doc.metadata.get('type') == \"excel\" else \"hari libur nasional\"\n",
        "        formatted.append(\n",
        "            f\"Jenis: {doc.metadata.get('type', 'unknown')}\\n\"\n",
        "            f\"Format: {doc.metadata.get('format', 'N/A')}\\n\"\n",
        "            f\"Sumber: {doc.metadata['source']}\\n\"\n",
        "            f\"Ringkasan: {content_summary}\\n\"\n",
        "            f\"Isi:\\n{doc.page_content[:2000]}...\"\n",
        "        )\n",
        "    return \"\\n\\n---\\n\\n\".join(formatted)\n",
        "\n",
        "# ============== MAIN APPLICATION ==============\n",
        "def main():\n",
        "    # Setup LLM\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.3)\n",
        "\n",
        "    # Load documents\n",
        "    folder_path = \"/content/drive/My Drive/Final Project Bootcamp/chatbot_docs/\"\n",
        "    documents = load_documents(folder_path)\n",
        "\n",
        "    if not documents:\n",
        "        print(\"❌ Tidak ada dokumen yang bisa diproses\")\n",
        "        return\n",
        "\n",
        "    # Create vector store\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    splits = text_splitter.split_documents(documents)\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    vectorstore = FAISS.from_documents(splits, embeddings)\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "    # Create chain\n",
        "    rag_chain = (\n",
        "        {\n",
        "            \"context\": retriever | format_docs,\n",
        "            \"question\": lambda x: x[\"question\"],\n",
        "            \"doc_type\": lambda x: \"Excel\" if \"excel\" in x[\"context\"].lower() else \"PDF\",\n",
        "            \"format\": lambda x: \"Jadwal Tim\" if \"jadwal_tim\" in x[\"context\"].lower() else \"Libur Nasional\",\n",
        "            \"content_summary\": lambda x: \"jadwal shift tim\" if \"jadwal_tim\" in x[\"context\"].lower() else \"hari libur dan cuti bersama\",\n",
        "            \"source\": lambda x: [d.metadata[\"source\"] for d in x[\"context\"].docs][0] if hasattr(x[\"context\"], 'docs') else \"Unknown\"\n",
        "        }\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    # Gradio interface\n",
        "    def respond(message, history):\n",
        "        response = rag_chain.invoke({\"question\": message})\n",
        "        return response.replace(\"1. Jenis Dokumen:\", \"\\n1. Jenis Dokumen:\").replace(\"2. Format:\", \"\\n2. Format:\")\n",
        "\n",
        "    demo = gr.ChatInterface(\n",
        "        respond,\n",
        "        title=\"Chatbot Jadwal Tim\",\n",
        "        description=\"Tanyakan tentang jadwal tim dari dokumen yang diupload. Contoh pertanyaan:\\n- 'Jadwal Ratih di bulan April'\\n- 'Siapa yang standby tanggal 15 April?'\\n- 'Hari libur di bulan Mei'\"\n",
        "    )\n",
        "    demo.launch(share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b151c52-20a3-432f-ab16-4721c16581c4",
      "metadata": {
        "id": "2b151c52-20a3-432f-ab16-4721c16581c4"
      },
      "source": [
        "## Submit Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ced6b581-708f-4758-86ff-3cd51bf14f99",
      "metadata": {
        "id": "ced6b581-708f-4758-86ff-3cd51bf14f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8ea80d7b-ef17-4944-d7d7-0199fdc7332b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Assignment successfully submitted'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "portfolio_link = \"https://github.com/arrdsj/DocuBot\"\n",
        "presentation_link = \"https://docs.google.com/presentation/d/1NNsNIM0Q6AC_zIojQHBdWvnOkkOHs_77/edit?usp=sharing&ouid=110604046736752212553&rtpof=true&sd=true\"\n",
        "\n",
        "question_id = \"01_portfolio_link\"\n",
        "submit(student_id, name, assignment_id, str(portfolio_link), question_id, drive_link)\n",
        "\n",
        "question_id = \"02_presentation_link\"\n",
        "submit(student_id, name, assignment_id, str(presentation_link), question_id, drive_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "792aa177-c74e-42e5-9881-40376cd746a8",
      "metadata": {
        "id": "792aa177-c74e-42e5-9881-40376cd746a8"
      },
      "source": [
        "# FIN"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}