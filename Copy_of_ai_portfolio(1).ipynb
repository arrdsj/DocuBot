{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be58b994-bc68-4166-91d5-282418b78864",
      "metadata": {
        "id": "be58b994-bc68-4166-91d5-282418b78864"
      },
      "source": [
        "# Project: Portfolio - Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5120b06-0abf-49e3-b54d-db8afa9eda01",
      "metadata": {
        "id": "c5120b06-0abf-49e3-b54d-db8afa9eda01"
      },
      "source": [
        "**Instructions for Students:**\n",
        "\n",
        "Please carefully follow these steps to complete and submit your assignment:\n",
        "\n",
        "1. **Completing the Assignment**: You are required to work on and complete all tasks in the provided assignment. Be disciplined and ensure that you thoroughly engage with each task.\n",
        "   \n",
        "2. **Creating a Google Drive Folder**: If you don't previously have a folder for collecting assignments, you must create a new folder in your Google Drive. This will be a repository for all your completed assignment files, helping you keep your work organized and easy to access.\n",
        "   \n",
        "3. **Uploading Completed Assignment**: Upon completion of your assignment, make sure to upload all necessary files, involving codes, reports, and related documents into the created Google Drive folder. Save this link in the 'Student Identity' section and also provide it as the last parameter in the `submit` function that has been provided.\n",
        "   \n",
        "4. **Sharing Folder Link**: You're required to share the link to your assignment Google Drive folder. This is crucial for the submission and evaluation of your assignment.\n",
        "   \n",
        "5. **Setting Permission toPublic**: Please make sure your **Google Drive folder is set to public**. This allows your instructor to access your solutions and assess your work correctly.\n",
        "\n",
        "Adhering to these procedures will facilitate a smooth assignment process for you and the reviewers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca56111-19cb-46c0-a77b-11bd18c55673",
      "metadata": {
        "id": "eca56111-19cb-46c0-a77b-11bd18c55673"
      },
      "source": [
        "**Description:**\n",
        "\n",
        "Welcome to your final portfolio project assignment for AI Bootcamp. This is your chance to put all the skills and knowledge you've learned throughout the bootcamp into action by creating real-world AI application.\n",
        "\n",
        "You have the freedom to create any application or model, be it text-based or image-based or even voice-based or multimodal.\n",
        "\n",
        "To get you started, here are some ideas:\n",
        "\n",
        "1. **Sentiment Analysis Application:** Develop an application that can determine sentiment (positive, negative, neutral) from text data like reviews or social media posts. You can use Natural Language Processing (NLP) libraries like NLTK or TextBlob, or more advanced pre-trained models from transformers library by Hugging Face, for your sentiment analysis model.\n",
        "\n",
        "2. **Chatbot:** Design a chatbot serving a specific purpose such as customer service for a certain industry, a personal fitness coach, or a study helper. Libraries like ChatterBot or Dialogflow can assist in designing conversational agents.\n",
        "\n",
        "3. **Predictive Text Application:** Develop a model that suggests the next word or sentence similar to predictive text on smartphone keyboards. You could use the transformers library by Hugging Face, which includes pre-trained models like GPT-2.\n",
        "\n",
        "4. **Image Classification Application:** Create a model to distinguish between different types of flowers or fruits. For this type of image classification task, pre-trained models like ResNet or VGG from PyTorch or TensorFlow can be utilized.\n",
        "\n",
        "5. **News Article Classifier:** Develop a text classification model that categorizes news articles into predefined categories. NLTK, SpaCy, and sklearn are valuable libraries for text pre-processing, feature extraction, and building classification models.\n",
        "\n",
        "6. **Recommendation System:** Create a simplified recommendation system. For instance, a book or movie recommender based on user preferences. Python's Surprise library can assist in building effective recommendation systems.\n",
        "\n",
        "7. **Plant Disease Detection:** Develop a model to identify diseases in plants using leaf images. This project requires a good understanding of convolutional neural networks (CNNs) and image processing. PyTorch, TensorFlow, and OpenCV are all great tools to use.\n",
        "\n",
        "8. **Facial Expression Recognition:** Develop a model to classify human facial expressions. This involves complex feature extraction and classification algorithms. You might want to leverage deep learning libraries like TensorFlow or PyTorch, along with OpenCV for processing facial images.\n",
        "\n",
        "9. **Chest X-Ray Interpretation:** Develop a model to detect abnormalities in chest X-ray images. This task may require understanding of specific features in such images. Again, TensorFlow and PyTorch for deep learning, and libraries like SciKit-Image or PIL for image processing, could be of use.\n",
        "\n",
        "10. **Food Classification:** Develop a model to classify a variety of foods such as local Indonesian food. Pre-trained models like ResNet or VGG from PyTorch or TensorFlow can be a good starting point.\n",
        "\n",
        "11. **Traffic Sign Recognition:** Design a model to recognize different traffic signs. This project has real-world applicability in self-driving car technology. Once more, you might utilize PyTorch or TensorFlow for the deep learning aspect, and OpenCV for image processing tasks.\n",
        "\n",
        "**Submission:**\n",
        "\n",
        "Please upload both your model and application to Huggingface or your own Github account for submission.\n",
        "\n",
        "**Presentation:**\n",
        "\n",
        "You are required to create a presentation to showcase your project, including the following details:\n",
        "\n",
        "- The objective of your model.\n",
        "- A comprehensive description of your model.\n",
        "- The specific metrics used to measure your model's effectiveness.\n",
        "- A brief overview of the dataset used, including its source, pre-processing steps, and any insights.\n",
        "- An explanation of the methodology used in developing the model.\n",
        "- A discussion on challenges faced, how they were handled, and your learnings from those.\n",
        "- Suggestions for potential future improvements to the model.\n",
        "- A functioning link to a demo of your model in action.\n",
        "\n",
        "**Grading:**\n",
        "\n",
        "Submissions will be manually graded, with a select few given the opportunity to present their projects in front of a panel of judges. This will provide valuable feedback, further enhancing your project and expanding your knowledge base.\n",
        "\n",
        "Remember, consistent practice is the key to mastering these concepts. Apply your knowledge, ask questions when in doubt, and above all, enjoy the process. Best of luck to you all!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "213a611a-c434-4894-ba35-689963ee5274",
      "metadata": {
        "id": "213a611a-c434-4894-ba35-689963ee5274"
      },
      "outputs": [],
      "source": [
        "# @title #### Student Identity\n",
        "student_id = \"REA6HXRRQ\" # @param {type:\"string\"}\n",
        "name = \"Ratih Dewi Setyo Jati\" # @param {type:\"string\"}\n",
        "drive_link = \"https://drive.google.com/drive/folders/1Vrjou0HK9_7a2qA6abCbjXJA6WRDqzBU?usp=sharing\"  # @param {type:\"string\"}\n",
        "assignment_id = \"00_portfolio_project\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c97aef3-b747-49f7-99e0-4086c03e4200",
      "metadata": {
        "id": "2c97aef3-b747-49f7-99e0-4086c03e4200"
      },
      "source": [
        "## Installation and Import `rggrader` Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c07e23-0280-467f-b0d2-44d966253bb4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36c07e23-0280-467f-b0d2-44d966253bb4",
        "outputId": "03fc8656-72df-4b95-e0ac-5ad346909bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rggrader\n",
            "  Downloading rggrader-0.1.6-py3-none-any.whl.metadata (485 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from rggrader) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from rggrader) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rggrader) (11.2.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->rggrader) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->rggrader) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->rggrader) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->rggrader) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->rggrader) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->rggrader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->rggrader) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->rggrader) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->rggrader) (1.17.0)\n",
            "Downloading rggrader-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: rggrader\n",
            "Successfully installed rggrader-0.1.6\n"
          ]
        }
      ],
      "source": [
        "%pip install rggrader\n",
        "from rggrader import submit_image\n",
        "from rggrader import submit\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4af3420-ff0e-472b-8b44-7a495ddf76c3",
      "metadata": {
        "id": "a4af3420-ff0e-472b-8b44-7a495ddf76c3"
      },
      "source": [
        "## Working Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1fb239a-1c81-4476-9009-d87abadf9506",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c1fb239a-1c81-4476-9009-d87abadf9506",
        "outputId": "bf911916-f3a6-483b-fe41-6bed7cc1677c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio)\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, PyPDF2, PyMuPDF, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed PyMuPDF-1.25.5 PyPDF2-3.0.1 aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.8 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n",
            "Masukkan Google Gemini API Key: AIzaSyC4C22jUntWRkYJfQrR2k2RgRnL07FoIC0\n",
            "Mounted at /content/drive\n",
            " Isi folder: ['JADWAL HD PSS APRIL 2025.xlsx', 'Jadwal Coverage + Onsite March 2025 - Tim Infraops System engineer-DBA.xlsx', 'Jadwal Coverage tim Network OIO-2 Maret 2025.xlsx', 'Pengumuman Libur Nasional dan Cuti Bersama 2025.pdf']\n",
            " Akan membaca 1 file PDF: ['Pengumuman Libur Nasional dan Cuti Bersama 2025.pdf']\n",
            " Membaca Pengumuman Libur Nasional dan Cuti Bersama 2025.pdf (2 halaman)\n",
            " Berhasil membaca Pengumuman Libur Nasional dan Cuti Bersama 2025.pdf\n",
            "Teks normalisasi (500 karakter): PENGUMUMAN Nomor : ASI/EHC/PE - 6019/2024 tentang HARI LIBUR NASIONAL DAN CUTI BERSAMA TAHUN 2025 PT AERO SYSTEM INDONESIA Sesuai Keputusan Bersama Menteri Agama, Menteri Ketenagakerjaan, dan Menteri Pendayagunaan Aparatur Negara dan Reformasi birokrasi Republik Indonesia Nomor 1017 tahun 2024, nomor 2 tahun 2024, nomor 2 tahun 2024 tentang Hari Libur Nasional dan Cuti Bersama Tahun 2025, dengan ini disampaikan penetapan Hari Libur Nasional dan Cuti Bersama Tahun 2025 beserta pelaksanaannya seba...\n",
            " Libur nasional ditemukan: 16\n",
            " Cuti bersama ditemukan: 6\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f08879018f92256629.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f08879018f92256629.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install PyMuPDF gradio google-generativeai PyPDF2 pandas openpyxl\n",
        "\n",
        "import PyPDF2\n",
        "import gradio as gr\n",
        "from google.colab import drive\n",
        "import google.generativeai as genai\n",
        "import re\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "\n",
        "# Variabel global untuk menyimpan log\n",
        "chat_log = []\n",
        "\n",
        "def add_to_log(message):\n",
        "    chat_log.append(message)\n",
        "    print(message)\n",
        "\n",
        "# Fungsi untuk membaca semua PDF dalam folder\n",
        "def extract_text_from_folder(folder_path):\n",
        "    all_text = \"\"\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        add_to_log(f\" Folder tidak ditemukan: {folder_path}\")\n",
        "        return None\n",
        "\n",
        "    if not os.path.isdir(folder_path):\n",
        "        add_to_log(f\" Path bukan folder: {folder_path}\")\n",
        "        return None\n",
        "\n",
        "    add_to_log(f\" Isi folder: {os.listdir(folder_path)}\")\n",
        "    pdf_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.pdf')]\n",
        "\n",
        "    if not pdf_files:\n",
        "        add_to_log(\" Tidak ada file PDF di folder ini\")\n",
        "        return None\n",
        "\n",
        "    add_to_log(f\" Akan membaca {len(pdf_files)} file PDF: {pdf_files}\")\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        file_path = os.path.join(folder_path, pdf_file)\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                add_to_log(f\" Membaca {pdf_file} ({len(reader.pages)} halaman)\")\n",
        "\n",
        "                for page in reader.pages:\n",
        "                    all_text += page.extract_text() + \"\\n---\\n\"\n",
        "\n",
        "            add_to_log(f\" Berhasil membaca {pdf_file}\")\n",
        "        except Exception as e:\n",
        "            add_to_log(f\" Gagal membaca {pdf_file}: {str(e)}\")\n",
        "\n",
        "    return all_text if all_text else None\n",
        "\n",
        "# Fungsi untuk memproses data libur\n",
        "def process_holiday_data(text):\n",
        "    national_holidays = []\n",
        "    joint_holidays = []\n",
        "\n",
        "    try:\n",
        "        text = text.replace('\\r', ' ').replace('\\n', ' ')\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        add_to_log(f\"Teks normalisasi (500 karakter): {text[:500]}...\")\n",
        "\n",
        "        parts = re.split(r'1\\.\\s*Hari\\s*libur\\s*nasional|2\\.\\s*Cuti\\s*bersama', text, flags=re.IGNORECASE)\n",
        "\n",
        "        if len(parts) < 3:\n",
        "            raise ValueError(\"Format dokumen tidak dikenali\")\n",
        "\n",
        "        national_section = parts[1]\n",
        "        national_pattern = re.compile(\n",
        "            r'(?P<no>\\d+)\\s+(?P<tanggal>\\d{1,2}\\s+[A-Za-z]+\\s*(?:\\-\\s*\\d{1,2}\\s+[A-Za-z]+)?)\\s+'\n",
        "            r'(?P<hari>[A-Za-z]+(?:\\s*\\-\\s*[A-Za-z]+)?)\\s+'\n",
        "            r'(?P<keterangan>.+?)(?=\\s*\\d+\\s+\\d{1,2}\\s+[A-Za-z]+|$)',\n",
        "            re.IGNORECASE\n",
        "        )\n",
        "\n",
        "        for match in national_pattern.finditer(national_section):\n",
        "            national_holidays.append({\n",
        "                'tanggal': match.group('tanggal').strip(),\n",
        "                'hari': match.group('hari').strip(),\n",
        "                'keterangan': match.group('keterangan').strip()\n",
        "            })\n",
        "\n",
        "        joint_section = parts[2]\n",
        "        joint_pattern = re.compile(\n",
        "            r'(?P<no>\\d+)\\s+(?P<tanggal>\\d{1,2}\\s*[A-Za-z]+\\s*(?:,\\s*\\d{1,2}\\s*[A-Za-z]+\\s*(?:dan\\s*\\d{1,2}\\s*[A-Za-z]+)?)?)\\s+'\n",
        "            r'(?P<hari>[A-Za-z]+)\\s+'\n",
        "            r'(?P<keterangan>.+?)(?=\\s*\\d+\\s+\\d{1,2}\\s*[A-Za-z]+|$)',\n",
        "            re.IGNORECASE\n",
        "        )\n",
        "\n",
        "        for match in joint_pattern.finditer(joint_section):\n",
        "            joint_holidays.append({\n",
        "                'tanggal': match.group('tanggal').strip(),\n",
        "                'hari': match.group('hari').strip(),\n",
        "                'keterangan': match.group('keterangan').strip()\n",
        "            })\n",
        "\n",
        "        add_to_log(f\" Libur nasional ditemukan: {len(national_holidays)}\")\n",
        "        add_to_log(f\" Cuti bersama ditemukan: {len(joint_holidays)}\")\n",
        "\n",
        "        return national_holidays, joint_holidays\n",
        "    except Exception as e:\n",
        "        add_to_log(f\" Error proses data: {str(e)}\")\n",
        "        return [], []\n",
        "\n",
        "def find_holidays_by_month(month, national_holidays, joint_holidays):\n",
        "    month_map = {\n",
        "        'januari': ['januari', 'jan'], 'februari': ['februari', 'feb'],\n",
        "        'maret': ['maret', 'mar'], 'april': ['april', 'apr'],\n",
        "        'mei': ['mei', 'mei'], 'juni': ['juni', 'jun'],\n",
        "        'juli': ['juli', 'jul'], 'agustus': ['agustus', 'agu', 'aug'],\n",
        "        'september': ['september', 'sep'], 'oktober': ['oktober', 'okt', 'oct'],\n",
        "        'november': ['november', 'nov'], 'desember': ['desember', 'des', 'dec']\n",
        "    }\n",
        "\n",
        "    target_months = month_map.get(month.lower(), [month.lower()])\n",
        "    result = []\n",
        "\n",
        "    for holiday in national_holidays:\n",
        "        holiday_month = re.search(r'(\\d{1,2}\\s+)([A-Za-z]+)', holiday['tanggal'])\n",
        "        if holiday_month and any(m in holiday_month.group(2).lower() for m in target_months):\n",
        "            result.append(f\" Libur Nasional: {holiday['tanggal']} ({holiday['hari']}) - {holiday['keterangan']}\")\n",
        "\n",
        "    for holiday in joint_holidays:\n",
        "        holiday_month = re.search(r'(\\d{1,2}\\s*)([A-Za-z]+)', holiday['tanggal'])\n",
        "        if holiday_month and any(m in holiday_month.group(2).lower() for m in target_months):\n",
        "            result.append(f\" Cuti Bersama: {holiday['tanggal']} ({holiday['hari']}) - {holiday['keterangan']}\")\n",
        "\n",
        "    return \"\\n\".join(result) if result else f\"Tidak ada libur di bulan {month.capitalize()}\"\n",
        "\n",
        "# Fungsi untuk memproses file Excel jadwal tim\n",
        "def process_schedule_file(file_path):\n",
        "    try:\n",
        "        xls = pd.ExcelFile(file_path)\n",
        "        sheets = {}\n",
        "\n",
        "        for sheet_name in xls.sheet_names:\n",
        "            df = pd.read_excel(xls, sheet_name=sheet_name, header=None)\n",
        "            sheets[sheet_name] = df\n",
        "\n",
        "        return sheets\n",
        "    except Exception as e:\n",
        "        add_to_log(f\" Gagal membaca file Excel: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def get_all_personnel_names(schedule_data):\n",
        "    \"\"\"Mendapatkan semua nama personel dari data jadwal\"\"\"\n",
        "    personnel_names = set()\n",
        "    for sheet_name, df in schedule_data.items():\n",
        "        for idx, row in df.iterrows():\n",
        "            if isinstance(row[0], str) and row[0].strip():\n",
        "                if idx > 3:  # Asumsi baris 0-3 adalah header\n",
        "                    name = row[0].split()[0]\n",
        "                    personnel_names.add(name.strip().title())\n",
        "    return sorted(list(personnel_names))\n",
        "\n",
        "def get_person_schedule(person_name, month, schedule_data):\n",
        "    try:\n",
        "        month = month.lower()[:3]  # Normalisasi ke 3 huruf pertama\n",
        "\n",
        "        # 1. Cari sheet yang mengandung nama bulan\n",
        "        target_sheet = None\n",
        "        for sheet_name, df in schedule_data.items():\n",
        "            if month in sheet_name.lower():\n",
        "                target_sheet = df\n",
        "                add_to_log(f\" Menggunakan sheet: {sheet_name}\")\n",
        "                break\n",
        "\n",
        "        # Jika tidak ditemukan, cari sheet dengan pola lain\n",
        "        if target_sheet is None:\n",
        "            for sheet_name, df in schedule_data.items():\n",
        "                if any(m in sheet_name.lower() for m in ['schedule', 'jadwal', 'tabel']):\n",
        "                    target_sheet = df\n",
        "                    add_to_log(f\" Menggunakan sheet alternatif: {sheet_name}\")\n",
        "                    break\n",
        "\n",
        "        # Jika masih tidak ditemukan, gunakan sheet pertama\n",
        "        if target_sheet is None:\n",
        "            target_sheet = next(iter(schedule_data.values()))\n",
        "            add_to_log(f\" Menggunakan sheet pertama: {list(schedule_data.keys())[0]}\")\n",
        "\n",
        "        # 2. Cari personel dengan pencarian lebih fleksibel\n",
        "        person_row = None\n",
        "        for idx, row in target_sheet.iterrows():\n",
        "            if isinstance(row[0], str) and person_name.lower() in row[0].lower().replace(\" \", \"\"):\n",
        "                person_row = row\n",
        "                add_to_log(f\" Ditemukan baris untuk {person_name} di baris {idx}\")\n",
        "                break\n",
        "\n",
        "        if person_row is None:\n",
        "            available_names = get_all_personnel_names(schedule_data)\n",
        "            return f\"Personel {person_name} tidak ditemukan. Yang tersedia: {', '.join(available_names)}\"\n",
        "\n",
        "        # 3. Ekstrak tanggal - cari baris yang berisi angka tanggal\n",
        "        dates = []\n",
        "        for row_idx in range(len(target_sheet)):\n",
        "            row = target_sheet.iloc[row_idx]\n",
        "            if any(isinstance(cell, (int, float)) and 1 <= cell <= 31 for cell in row[1:] if pd.notna(cell)):\n",
        "                date_row_idx = row_idx\n",
        "                add_to_log(f\" Baris tanggal ditemukan di baris {date_row_idx}\")\n",
        "                break\n",
        "\n",
        "        # 4. Kumpulkan jadwal\n",
        "        schedule_entries = []\n",
        "        if 'date_row_idx' in locals():\n",
        "            date_row = target_sheet.iloc[date_row_idx]\n",
        "            for col in range(1, len(person_row)):\n",
        "                if col < len(date_row) and pd.notna(date_row[col]):\n",
        "                    try:\n",
        "                        date_val = int(float(date_row[col]))\n",
        "                        shift = person_row[col] if col < len(person_row) and pd.notna(person_row[col]) else None\n",
        "                        if shift:\n",
        "                            # Cari nama hari di baris berikutnya\n",
        "                            day_name = target_sheet.iloc[date_row_idx+1, col] if (date_row_idx+1) < len(target_sheet) else ''\n",
        "                            schedule_entries.append((date_val, str(shift).strip(), str(day_name).strip()))\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "        # 5. Format output\n",
        "        result = f\" Jadwal {person_name.title()} - April 2025:\\n\"\n",
        "        if not schedule_entries:\n",
        "            result += \"Tidak ada jadwal yang ditemukan\\n\"\n",
        "            # Debug info\n",
        "            result += f\"\\nDebug Info:\\n- Sheet: {list(schedule_data.keys())}\\n\"\n",
        "            result += f\"- Baris tanggal: {'ditemukan' if 'date_row_idx' in locals() else 'tidak ditemukan'}\\n\"\n",
        "        else:\n",
        "            for date, shift, day_name in sorted(schedule_entries, key=lambda x: x[0]):\n",
        "                result += f\"{date:02d} Apr: {shift}\"\n",
        "                if day_name:\n",
        "                    result += f\" ({day_name})\"\n",
        "                result += \"\\n\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        add_to_log(f\" Error: {str(e)}\")\n",
        "        return f\"Terjadi error saat memproses jadwal {person_name}\"\n",
        "\n",
        "        # 6. Hitung total shift\n",
        "        shift_counts = {\n",
        "            'Shift 1 (P)': 0,\n",
        "            'Shift 2 (S)': 0,\n",
        "            'Shift 3 (M)': 0,\n",
        "            'Leave (L)': 0,\n",
        "            'Cuti (C)': 0,\n",
        "            'Lainnya': 0\n",
        "        }\n",
        "\n",
        "        for _, shift, _ in schedule_entries:\n",
        "            shift = shift.upper()\n",
        "            if 'P' in shift:\n",
        "                shift_counts['Shift 1 (P)'] += 1\n",
        "            if 'S' in shift:\n",
        "                shift_counts['Shift 2 (S)'] += 1\n",
        "            if 'M' in shift:\n",
        "                shift_counts['Shift 3 (M)'] += 1\n",
        "            if shift == 'L':\n",
        "                shift_counts['Leave (L)'] += 1\n",
        "            if shift == 'C':\n",
        "                shift_counts['Cuti (C)'] += 1\n",
        "            if shift not in ['P', 'S', 'M', 'L', 'C']:\n",
        "                shift_counts['Lainnya'] += 1\n",
        "\n",
        "        result += \"\\nTotal:\\n\"\n",
        "        for shift_type, count in shift_counts.items():\n",
        "            if count > 0:\n",
        "                result += f\"- {shift_type}: {count} hari\\n\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        add_to_log(f\" Error: {str(e)}\")\n",
        "        return f\"Terjadi error saat memproses jadwal {person_name}\"\n",
        "\n",
        "def get_personnel_by_date(date, month, schedule_data):\n",
        "    try:\n",
        "        target_sheet = None\n",
        "        month = month.lower()[:3] if month else 'apr'\n",
        "\n",
        "        for sheet_name, df in schedule_data.items():\n",
        "            if month in sheet_name.lower()[:3]:\n",
        "                target_sheet = df\n",
        "                break\n",
        "\n",
        "        if target_sheet is None:\n",
        "            target_sheet = next(iter(schedule_data.values()))\n",
        "\n",
        "        date_col = None\n",
        "        header_row = 3\n",
        "\n",
        "        for col in range(len(target_sheet.columns)):\n",
        "            if header_row < len(target_sheet):\n",
        "                date_cell = target_sheet.iloc[header_row, col]\n",
        "                if pd.notna(date_cell) and isinstance(date_cell, (int, float)) and int(float(date_cell)) == date:\n",
        "                    date_col = col\n",
        "                    break\n",
        "\n",
        "        if date_col is None:\n",
        "            return f\"Tidak menemukan jadwal untuk tanggal {date} {month.capitalize()}\"\n",
        "\n",
        "        personnel = []\n",
        "\n",
        "        for idx, row in target_sheet.iterrows():\n",
        "            if isinstance(row[0], str) and idx > header_row:\n",
        "                person_name = row[0].split()[0]\n",
        "                shift = row[date_col] if date_col < len(row) and pd.notna(row[date_col]) else None\n",
        "                if shift:\n",
        "                    personnel.append((person_name, shift))\n",
        "\n",
        "        result = f\"ğŸ‘¥ Personel pada {date} {month.capitalize()} 2025:\\n\"\n",
        "        for person, shift in personnel:\n",
        "            result += f\"- {person}: {shift}\\n\"\n",
        "\n",
        "        shift_types = set([s for _, s in personnel])\n",
        "        result += \"\\nShift yang tersedia:\\n\"\n",
        "        for shift in shift_types:\n",
        "            count = len([p for p, s in personnel if s == shift])\n",
        "            result += f\"- {shift}: {count} orang\\n\"\n",
        "\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        add_to_log(f\" Error mencari personel: {str(e)}\")\n",
        "        return f\"Terjadi error saat mencari personel untuk tanggal {date} {month.capitalize()}\"\n",
        "\n",
        "def main():\n",
        "    api_key = input(\"Masukkan Google Gemini API Key: \")\n",
        "    genai.configure(api_key=api_key)\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    folder_path = '/content/drive/MyDrive/Final Project Bootcamp/chatbot_docs'\n",
        "\n",
        "    combined_text = extract_text_from_folder(folder_path)\n",
        "\n",
        "    national_holidays, joint_holidays = [], []\n",
        "    if combined_text:\n",
        "        national_holidays, joint_holidays = process_holiday_data(combined_text)\n",
        "\n",
        "    schedule_data = None\n",
        "    excel_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.xlsx', '.xls'))]\n",
        "\n",
        "    if excel_files:\n",
        "        excel_file = excel_files[0]\n",
        "        excel_path = os.path.join(folder_path, excel_file)\n",
        "        schedule_data = process_schedule_file(excel_path)\n",
        "\n",
        "    def chatbot(question, history=None):\n",
        "        add_to_log(f\"\\n Pertanyaan: {question}\")\n",
        "\n",
        "        try:\n",
        "            personnel_list = get_all_personnel_names(schedule_data) if schedule_data else []\n",
        "\n",
        "            personel_dicari = None\n",
        "            for name in personnel_list:\n",
        "                if name.lower() in question.lower():\n",
        "                    personel_dicari = name\n",
        "                    break\n",
        "\n",
        "            tanggal_dicari = None\n",
        "            bulan_dicari = None\n",
        "            date_match = re.search(r'(\\d{1,2})\\s*(april|apr|maret|mar|mei|juni|jun|juli|jul|agustus|agu|aug|september|sep|oktober|okt|oct|november|nov|desember|des|dec)',\n",
        "                                 question.lower())\n",
        "            if date_match:\n",
        "                tanggal_dicari = int(date_match.group(1))\n",
        "                bulan_dicari = date_match.group(2)\n",
        "\n",
        "            if not personel_dicari and not tanggal_dicari:\n",
        "                for bulan in ['januari', 'februari', 'maret', 'april', 'mei', 'juni',\n",
        "                             'juli', 'agustus', 'september', 'oktober', 'november', 'desember']:\n",
        "                    if bulan in question.lower():\n",
        "                        bulan_dicari = bulan\n",
        "                        break\n",
        "\n",
        "            if personel_dicari and schedule_data:\n",
        "                bulan_pertanyaan = bulan_dicari if bulan_dicari else 'april'\n",
        "                response = get_person_schedule(personel_dicari, bulan_pertanyaan, schedule_data)\n",
        "                add_to_log(f\" Jawaban dari jadwal tim: {response[:200]}...\")\n",
        "\n",
        "            elif tanggal_dicari and schedule_data:\n",
        "                response = get_personnel_by_date(tanggal_dicari, bulan_dicari, schedule_data)\n",
        "                add_to_log(f\" Jawaban dari jadwal tim: {response[:200]}...\")\n",
        "\n",
        "            elif bulan_dicari and national_holidays and joint_holidays:\n",
        "                response = find_holidays_by_month(bulan_dicari, national_holidays, joint_holidays)\n",
        "                add_to_log(f\" Jawaban dari data libur: {response}\")\n",
        "\n",
        "            else:\n",
        "                response = model.generate_content(question).text\n",
        "                add_to_log(f\" Jawaban dari Gemini: {response}\")\n",
        "\n",
        "            return response, \"\\n\".join(chat_log[-5:])\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\" Error: {str(e)}\"\n",
        "            add_to_log(error_msg)\n",
        "            return error_msg, \"\\n\".join(chat_log[-5:])\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"##  Chatbot Jadwal Tim & Libur Nasional\")\n",
        "        gr.Markdown(\"Tanyakan tentang jadwal tim atau hari libur dan cuti bersama tahun 2025\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                question = gr.Textbox(label=\"Tanya tentang jadwal atau libur\",\n",
        "                                    placeholder=\"Contoh: Tampilkan jadwal Ratih untuk April 2025\")\n",
        "                submit_btn = gr.Button(\"Kirim\")\n",
        "\n",
        "            with gr.Column():\n",
        "                output = gr.Textbox(label=\"Jawaban\")\n",
        "                console = gr.Textbox(label=\"Console Log\", interactive=False, lines=5)\n",
        "\n",
        "        submit_btn.click(\n",
        "            fn=chatbot,\n",
        "            inputs=question,\n",
        "            outputs=[output, console]\n",
        "        )\n",
        "\n",
        "        question.submit(\n",
        "            fn=chatbot,\n",
        "            inputs=question,\n",
        "            outputs=[output, console]\n",
        "        )\n",
        "\n",
        "    demo.launch(share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b151c52-20a3-432f-ab16-4721c16581c4",
      "metadata": {
        "id": "2b151c52-20a3-432f-ab16-4721c16581c4"
      },
      "source": [
        "## Submit Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ced6b581-708f-4758-86ff-3cd51bf14f99",
      "metadata": {
        "id": "ced6b581-708f-4758-86ff-3cd51bf14f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dd7bdc33-2bd1-4b06-a1bd-6d1ce3cc3a98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Assignment successfully submitted'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "portfolio_link = \"https://github.com/arrdsj/DocuBot\"\n",
        "presentation_link = \"https://docs.google.com/presentation/d/1NNsNIM0Q6AC_zIojQHBdWvnOkkOHs_77/edit?usp=sharing&ouid=110604046736752212553&rtpof=true&sd=true\"\n",
        "\n",
        "question_id = \"01_portfolio_link\"\n",
        "submit(student_id, name, assignment_id, str(portfolio_link), question_id, drive_link)\n",
        "\n",
        "question_id = \"02_presentation_link\"\n",
        "submit(student_id, name, assignment_id, str(presentation_link), question_id, drive_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "792aa177-c74e-42e5-9881-40376cd746a8",
      "metadata": {
        "id": "792aa177-c74e-42e5-9881-40376cd746a8"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}